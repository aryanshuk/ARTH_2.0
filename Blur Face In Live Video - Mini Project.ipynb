{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46f1811",
   "metadata": {},
   "source": [
    "# Blur the Face of a Person in a Live Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60cfd2",
   "metadata": {},
   "source": [
    "## Steps : \n",
    " ### 1. Detect face\n",
    " ### 2. Find position of the face\n",
    " ### 3. Crop the face \n",
    " ### 4. Blur the face \n",
    " ### 5. Replace the blurred face in original image\n",
    " ### 6. Repeat this in a loop for making live video with single blurred face\n",
    " ### 7. Repeat this in a loop for making live video with multiple blurred faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3680c00",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1d861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836143d",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Importing \"haarcascade_frontalface_default.xml\" model for detecting face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2f2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0d9d6",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Importing and testing the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2a7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b152a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo = cam.read()\n",
    "cv2.imshow(\"hii\",photo)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38479098",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Using haar cascade model for detecting face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f049ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceDetected = model.detectMultiScale(photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bce15b",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Finding position of the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28856942",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = faceDetected[0][0]\n",
    "y1 = faceDetected[0][1]\n",
    "x2 = faceDetected[0][2] + x1\n",
    "y2 = faceDetected[0][3] + y1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b090da90",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Cropping the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf7a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo = cam.read()\n",
    "faceDetected = model.detectMultiScale(photo)\n",
    "x1 = faceDetected[0][0]\n",
    "y1 = faceDetected[0][1]\n",
    "x2 = faceDetected[0][2] + x1\n",
    "y2 = faceDetected[0][3] + y1\n",
    "face = photo[y1:y2,x1:x2]\n",
    "cv2.imshow(\"hii\",face)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091e117",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Blurring the cropped face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24bc517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo = cam.read()\n",
    "faceDetected = model.detectMultiScale(photo)\n",
    "x1 = faceDetected[0][0]\n",
    "y1 = faceDetected[0][1]\n",
    "x2 = faceDetected[0][2] + x1\n",
    "y2 = faceDetected[0][3] + y1\n",
    "face = photo[y1:y2,x1:x2]\n",
    "blur_face = cv2.blur(face,(25,25))\n",
    "cv2.imshow(\"hii\",blur_face)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1269f97a",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Replacing the blurred face in original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5115076",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo = cam.read()\n",
    "faceDetected = model.detectMultiScale(photo)\n",
    "x1 = faceDetected[0][0]\n",
    "y1 = faceDetected[0][1]\n",
    "x2 = faceDetected[0][2] + x1\n",
    "y2 = faceDetected[0][3] + y1\n",
    "face = photo[y1:y2,x1:x2]\n",
    "blur_face = cv2.blur(face,(25,25))\n",
    "photo[y1:y2,x1:x2] = blur_face\n",
    "cv2.imshow(\"hii\",photo)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa5793",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "# Repeat above steps in a loop for making live video with blurred face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1849526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    ret,photo = cam.read()\n",
    "    faceDetected = model.detectMultiScale(photo)\n",
    "    x1 = faceDetected[0][0]\n",
    "    y1 = faceDetected[0][1]\n",
    "    x2 = faceDetected[0][2] + x1\n",
    "    y2 = faceDetected[0][3] + y1\n",
    "    face = photo[y1:y2,x1:x2]\n",
    "    blur_face = cv2.blur(face,(25,25))\n",
    "    photo[y1:y2,x1:x2] = blur_face\n",
    "    cv2.imshow(\"hii\",photo)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e80bb",
   "metadata": {},
   "source": [
    "# Note : This will crash when there isn't any face in the video because faceDetected will not have any value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04e798",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# We need to put an if statement which will not use faceDetected variable if no face is detected and it will solve the above problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3529675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,photo = cam.read()\n",
    "    faceDetected = model.detectMultiScale(photo)\n",
    "    faceDetectedNum = len(faceDetected)\n",
    "    if faceDetectedNum == 0:\n",
    "        cv2.imshow(\"Live Video : Say Hii\",photo)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "    else:\n",
    "        x1 = faceDetected[0][0]\n",
    "        y1 = faceDetected[0][1]\n",
    "        x2 = faceDetected[0][2] + x1\n",
    "        y2 = faceDetected[0][3] + y1\n",
    "        face = photo[y1:y2,x1:x2]\n",
    "        blur_face = cv2.blur(face,(25,25))\n",
    "        photo[y1:y2,x1:x2] = blur_face\n",
    "        cv2.imshow(\"Live Video : Say Hii\",photo)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f1f67",
   "metadata": {},
   "source": [
    "# NOTE : This code will blur only one face since position of face is fixed to first 1D array/first element of the 2D array returned by the model.detectMultiScale()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8331d",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# We need to run a loop for changing the face position for different faces detected. This will blur 'n' number of detected faces in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc52220",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,photo = cam.read()\n",
    "    faceDetected = model.detectMultiScale(photo)\n",
    "    faceDetectedNum = len(faceDetected)\n",
    "    if faceDetectedNum == 0:\n",
    "        cv2.imshow(\"Live Video : Say Hii\",photo)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "    else:\n",
    "        n = faceDetectedNum\n",
    "        while n > 0:\n",
    "            x1 = faceDetected[n - 1][0]\n",
    "            y1 = faceDetected[n - 1][1]\n",
    "            x2 = faceDetected[n - 1][2] + x1\n",
    "            y2 = faceDetected[n - 1][3] + y1\n",
    "            face = photo[y1:y2,x1:x2]\n",
    "            blur_face = cv2.blur(face,(25,25))\n",
    "            photo[y1:y2,x1:x2] = blur_face\n",
    "            n = n - 1\n",
    "        cv2.imshow(\"Live Video : Say Hii\",photo)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11135b8e",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# That's it. We have created a Python Code for detecting the faces in a live video using haarcascade_frontalface_default.xml model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb4ead",
   "metadata": {},
   "source": [
    "# Releasing the camera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99067849",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82290b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
